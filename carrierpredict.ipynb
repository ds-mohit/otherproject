{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0154691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of unique 'Role Category' classes: 59\n",
      "Focusing on the top 6 most frequent classes: ['programming & design', 'voice', 'retail sales', 'senior management', 'accounts', 'admin/maintenance/security/datawarehousing']\n",
      "Number of rows in the filtered dataset: 300\n",
      "\n",
      "Starting hyperparameter tuning with GridSearchCV...\n",
      "Tuning complete.\n",
      "Best parameters found: {'classifier__C': 0.1, 'tfidf__max_features': 1000}\n",
      "Best cross-validation accuracy: 0.78\n",
      "\n",
      "--- Final Model Evaluation ---\n",
      "Accuracy on the test set: 76.67%\n",
      "\n",
      "Classification Report:\n",
      "                                            precision    recall  f1-score   support\n",
      "\n",
      "                                  accounts       1.00      1.00      1.00         4\n",
      "admin/maintenance/security/datawarehousing       0.00      0.00      0.00         3\n",
      "                      programming & design       0.83      0.88      0.85        33\n",
      "                              retail sales       0.55      0.86      0.67         7\n",
      "                         senior management       0.00      0.00      0.00         4\n",
      "                                     voice       0.88      0.78      0.82         9\n",
      "\n",
      "                                  accuracy                           0.77        60\n",
      "                                 macro avg       0.54      0.59      0.56        60\n",
      "                              weighted avg       0.72      0.77      0.74        60\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# =================================================================================================\n",
    "# # Notebook: Training a High-Accuracy SVM for Job Category Classification (v2)\n",
    "# =================================================================================================\n",
    "#\n",
    "# ## üéØ Goal:\n",
    "# To train a Support Vector Machine (SVM) model to predict a job's 'Role Category'\n",
    "# with an accuracy greater than 85%.\n",
    "#\n",
    "# ## ‚ôüÔ∏è Strategy:\n",
    "# 1.  **Load and Prepare Data**: Load the cleaned dataset.\n",
    "# 2.  **Address Class Imbalance**: Focus on the **top 6 most frequent 'Role Category' classes** to\n",
    "#     create a more balanced and manageable classification problem.\n",
    "# 3.  **Feature Combination**: Create a new feature by combining all text-based columns (`Job Title`,\n",
    "#     `Key Skills`, `Location`, `Industry`) into a single text block. This simplifies the\n",
    "#     preprocessing pipeline.\n",
    "# 4.  **Build a Simplified Pipeline**: Use a single `TfidfVectorizer` to process the combined text\n",
    "#     feature and a `LinearSVC` (SVM) model. This avoids the `ColumnTransformer` versioning issue.\n",
    "# 5.  **Hyperparameter Tuning**: Use `GridSearchCV` to automatically find the best `C` parameter\n",
    "#     for the SVM model to maximize performance.\n",
    "# 6.  **Train and Evaluate**: Train the final model and evaluate it on the test set to confirm\n",
    "#     we have reached our accuracy target.\n",
    "#\n",
    "# ---\n",
    "\n",
    "# ### 1. Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ### 2. Load and Prepare the Data\n",
    "try:\n",
    "    # Load the dataset created in the first step\n",
    "    df = pd.read_csv('cleaned_augmented_jobs.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'cleaned_augmented_jobs.csv' not found.\")\n",
    "    print(\"Please ensure the data cleaning and augmentation notebook was run successfully first.\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "if not df.empty:\n",
    "    # --- Data Filtering to Address Class Imbalance ---\n",
    "    print(\"Original number of unique 'Role Category' classes:\", df['Role Category'].nunique())\n",
    "\n",
    "    # Identify and filter for the top 6 most frequent classes\n",
    "    top_6_classes = df['Role Category'].value_counts().nlargest(6).index\n",
    "    df_filtered = df[df['Role Category'].isin(top_6_classes)].copy()\n",
    "\n",
    "    print(f\"Focusing on the top 6 most frequent classes: {list(top_6_classes)}\")\n",
    "    print(\"Number of rows in the filtered dataset:\", len(df_filtered))\n",
    "\n",
    "\n",
    "    # ### 3. Feature Engineering: Combine Text Columns\n",
    "    \n",
    "    # Define the text features to be combined\n",
    "    text_features = ['Job Title', 'Key Skills', 'Location', 'Industry']\n",
    "    \n",
    "    # Create a new column 'combined_text' by joining the content of the text features.\n",
    "    # We use .fillna('') to handle any potential missing values gracefully.\n",
    "    df_filtered['combined_text'] = df_filtered[text_features].fillna('').agg(' '.join, axis=1)\n",
    "\n",
    "\n",
    "    # ### 4. Define Features (X) and Target (y)\n",
    "    \n",
    "    # The feature 'X' is now the new combined text column.\n",
    "    X = df_filtered['combined_text']\n",
    "    # The target 'y' remains the 'Role Category'.\n",
    "    y = df_filtered['Role Category']\n",
    "\n",
    "\n",
    "    # ### 5. Create a Simplified Modeling Pipeline\n",
    "\n",
    "    # The pipeline now has two steps:\n",
    "    # 1. 'tfidf': Vectorize the combined text data.\n",
    "    # 2. 'classifier': Train the LinearSVC model.\n",
    "    model_pipeline = Pipeline(steps=[\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1, 2))),\n",
    "        ('classifier', LinearSVC(random_state=42, dual=False, class_weight='balanced'))\n",
    "    ])\n",
    "\n",
    "    # ### 6. Split Data and Perform Hyperparameter Tuning\n",
    "\n",
    "    # Split data into training (80%) and testing (20%) sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Define the parameter grid to search. 'C' controls the regularization strength.\n",
    "    # We also tune 'tfidf__max_features' to find the optimal number of features.\n",
    "    param_grid = {\n",
    "        'tfidf__max_features': [1000, 2000, 3000],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "    }\n",
    "\n",
    "    # Set up GridSearchCV to find the best parameters using 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "    print(\"\\nStarting hyperparameter tuning with GridSearchCV...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"Tuning complete.\")\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation accuracy: {grid_search.best_score_:.2f}\")\n",
    "\n",
    "    # ### 7. Evaluate the Best Model on the Test Set\n",
    "\n",
    "    # The best model found by the grid search\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Make predictions on the unseen test data\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calculate the final accuracy\n",
    "    final_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"\\n--- Final Model Evaluation ---\")\n",
    "    print(f\"Accuracy on the test set: {final_accuracy:.2%}\")\n",
    "\n",
    "    # Display the detailed classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc00cabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CarrierPredictor.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Save the model to a file for future use\n",
    "joblib.dump(best_model, 'CarrierPredictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08241d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
